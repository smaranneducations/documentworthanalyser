// ═══════════════════════════════════════════════════════════════════════════
// Catalogue of Key Terms, Metrics & Labels — Assessment Rules
// Each entry: term, category, what it means, why it matters, how it's calculated
// Updated for hybrid Gemini AI + heuristic engine architecture.
// ═══════════════════════════════════════════════════════════════════════════

export interface GlossaryEntry {
  term: string;
  category: string;
  meaning: string;
  importance: string;
  calculation: string;
}

export const GLOSSARY: GlossaryEntry[] = [
  // ── Overall ───────────────────────────────────────────────────────────────
  {
    term: "Overall Trust Score",
    category: "Overall",
    meaning: "A composite score from 0-100 that represents the overall trustworthiness of the document based on all analysis modules.",
    importance: "Provides a single at-a-glance number to decide whether a document deserves serious attention or should be treated with scepticism.",
    calculation: "Generated by Gemini in the final synthesis layer (Layer 4). AI considers all prior analysis — forensics, readiness, obsolescence, hype, bias, and strategic positioning — to produce a holistic score. Falls back to weighted heuristic average if Gemini is unavailable.",
  },
  {
    term: "File Hash (SHA-256)",
    category: "Overall",
    meaning: "A unique cryptographic fingerprint of the uploaded file, generated using the SHA-256 algorithm.",
    importance: "Prevents duplicate analyses — if the same document is uploaded again, the system recognises it and returns the existing report instead of re-processing.",
    calculation: "The binary contents of the file are passed through the SHA-256 hash function, producing a fixed 64-character hexadecimal string. Computed client-side using crypto-js.",
  },
  {
    term: "Confidence",
    category: "Overall",
    meaning: "The AI's certainty in a classification result, expressed as a percentage.",
    importance: "Helps readers understand how strong the signals are. A 90% confidence classification is much more reliable than a 55% one.",
    calculation: "Generated by Gemini for each classification module. AI self-assesses based on the number, strength, and consistency of signals found across the document.",
  },

  // ── Module 1: Provider vs Consumer ────────────────────────────────────────
  {
    term: "Provider vs. Consumer",
    category: "Core Decision Modules",
    meaning: "Determines whether the document primarily serves the vendor's interests (upselling, lock-in) or empowers the reader to act independently.",
    importance: "Reveals hidden commercial motives. A 'thought leadership' paper that's really a sales pitch should be evaluated differently than genuinely educational content.",
    calculation: "Gemini Layer 3 classification. AI evaluates five weighted drivers using the document text plus deception, bias, and fluff findings from prior layers. Returns drivers (1-10 each), composite score (0-100), and classification.",
  },
  {
    term: "Problem Definition Clarity",
    category: "Core Decision Modules",
    meaning: "Measures whether the document frames problems as needing external help (provider-favored) or as solvable by the reader's team (consumer-favored).",
    importance: "Documents that make problems seem impossibly complex without the vendor's help are a red flag for commercial bias.",
    calculation: "Gemini scores 1-10 by analyzing how the document frames problems: dependency language ('you need experts') vs. empowerment language ('your team can'). Weight: 20%.",
  },
  {
    term: "Vendor Lock-in Potential",
    category: "Core Decision Modules",
    meaning: "Measures dependency creation on specific vendors, proprietary tools, or locked-in methodologies.",
    importance: "High lock-in means switching costs will be enormous. Open/interoperable recommendations are better for the consumer.",
    calculation: "Gemini scores 1-10 by detecting proprietary tool mentions, single-vendor recommendations, absence of alternatives, and migration difficulty language. Weight: 20%.",
  },
  {
    term: "Implementation Autonomy",
    category: "Core Decision Modules",
    meaning: "Whether the reader can execute the recommendations independently without hiring the document's author.",
    importance: "True thought leadership empowers. Documents that require 'call us for Phase 2' are sales funnels, not knowledge assets.",
    calculation: "Gemini scores 1-10 by assessing completeness of instructions, presence of self-service paths vs. 'contact us' patterns. Weight: 20%.",
  },
  {
    term: "Upsell Visibility",
    category: "Core Decision Modules",
    meaning: "Presence of 'Phase 2' mentions, premium tiers, 'contact us for more', or expansion opportunities that suggest revenue generation motive.",
    importance: "Frequent upsell patterns indicate the document's primary purpose is lead generation rather than knowledge sharing.",
    calculation: "Gemini scores 1-10 by evaluating density and prominence of upsell patterns in context. Higher score = less upselling. Weight: 20%.",
  },
  {
    term: "Risk Transfer",
    category: "Core Decision Modules",
    meaning: "Who bears the implementation risk — the vendor (with SLAs/guarantees) or the client?",
    importance: "Providers who transfer all risk to the client while retaining revenue are not aligned with consumer interests.",
    calculation: "Gemini scores 1-10 by detecting SLA mentions, guarantees, shared risk models vs. disclaimer-heavy, no-warranty language. Weight: 20%.",
  },

  // ── Module 2: Originator Scale ────────────────────────────────────────────
  {
    term: "Originator Scale",
    category: "Core Decision Modules",
    meaning: "Detects the likely size of the organization that created the document — Solo/Boutique, Mid-tier, or Big 4/GSI.",
    importance: "Context matters. A Big 4 paper promoting enterprise transformation is normal; a 2-person consultancy claiming the same breadth is suspect.",
    calculation: "Gemini Layer 3 classification using five weighted drivers. AI evaluates tone, branding, framework sophistication, data depth, and legal density.",
  },
  {
    term: "Framework Proprietary Level",
    category: "Core Decision Modules",
    meaning: "Whether the document uses generic frameworks (SWOT, Porter's) or branded proprietary IP with ©/®/™ marks.",
    importance: "Proprietary frameworks suggest larger firms with R&D investment. Generic frameworks suggest smaller firms repackaging common knowledge.",
    calculation: "Gemini scores 1-10 by evaluating framework sophistication and branding indicators. Weight: 30%.",
  },
  {
    term: "Data Scope & Depth",
    category: "Core Decision Modules",
    meaning: "Whether data comes from desk research and secondary citations (smaller firms) or primary global surveys and benchmarking (GSI resources).",
    importance: "Primary research with large sample sizes is more credible. Secondary data compilation is lower effort and potentially cherry-picked.",
    calculation: "Gemini scores 1-10 by assessing data source quality, sample sizes, and research methodology indicators. Weight: 20%.",
  },
  {
    term: "Design Polish & Branding",
    category: "Core Decision Modules",
    meaning: "Whether the document appears template-based or has studio-grade branding with professional design elements.",
    importance: "Investment in presentation quality correlates (though imperfectly) with organizational resources and professionalism.",
    calculation: "Gemini scores 1-10 by detecting copyright notices, trademarks, and professional language patterns. Weight: 15%.",
  },
  {
    term: "Service Breadth",
    category: "Core Decision Modules",
    meaning: "Whether the document covers niche specialisation or end-to-end transformation capability.",
    importance: "Claims of enterprise-wide capability from a small firm are a credibility mismatch. Niche depth from a specialist may be more valuable.",
    calculation: "Gemini scores 1-10 by counting and evaluating service area claims. More areas = broader claim. Weight: 15%.",
  },
  {
    term: "Legal/Compliance Density",
    category: "Core Decision Modules",
    meaning: "Amount of disclaimer, NDA, liability, and legal language in the document.",
    importance: "Heavy legal language suggests a large organization with legal departments. Informal language suggests smaller operations.",
    calculation: "Gemini scores 1-10 by evaluating density and sophistication of legal/compliance language. Weight: 20%.",
  },

  // ── Module 3: Target Scale ────────────────────────────────────────────────
  {
    term: "Target Company Scale",
    category: "Core Decision Modules",
    meaning: "The intended organizational audience — Startup (agile/MVP), SME (balanced), or Enterprise (governance-heavy).",
    importance: "A startup applying enterprise-grade governance will waste resources. An enterprise ignoring compliance will face regulatory risk.",
    calculation: "Gemini Layer 3 classification. Five weighted drivers evaluated with context from data intensity and regulatory findings in prior layers.",
  },
  {
    term: "Governance Complexity",
    category: "Core Decision Modules",
    meaning: "Whether the document mentions small teams (startup) or steering committees and board approvals (enterprise).",
    importance: "Governance requirements directly impact implementation speed and cost. Mismatched governance = project failure risk.",
    calculation: "Gemini scores 1-10 by analyzing governance structures, approval layers, and organizational complexity. Weight: 25%.",
  },
  {
    term: "Cross-Functional Impact",
    category: "Core Decision Modules",
    meaning: "Whether recommendations affect a single department or require enterprise-wide coordination.",
    importance: "Cross-functional projects have higher failure rates and need dedicated change management. Single-department scope is simpler.",
    calculation: "Gemini scores 1-10 by detecting scope of organizational impact described. Weight: 20%.",
  },
  {
    term: "Legacy Integration Focus",
    category: "Core Decision Modules",
    meaning: "Whether the document assumes greenfield (build new) or requires legacy system modernization/migration.",
    importance: "Legacy integration is the #1 cost overrun factor in IT projects. Greenfield assumptions are often unrealistic for established companies.",
    calculation: "Gemini scores 1-10 by comparing legacy vs. greenfield language and assumptions. Weight: 20%.",
  },
  {
    term: "Budget/Resource Implication",
    category: "Core Decision Modules",
    meaning: "Whether costs suggest SaaS subscriptions (small scale) or multi-year capital transformation programs (enterprise).",
    importance: "Budget mismatches are the fastest way to kill a project. Enterprise proposals for startup budgets will fail.",
    calculation: "Gemini scores 1-10 by evaluating budget language and resource implications. Weight: 15%.",
  },
  {
    term: "Risk & Security Standards",
    category: "Core Decision Modules",
    meaning: "Whether security mentions are basic or reference enterprise frameworks (SOC2, GDPR, ISO 27001).",
    importance: "Enterprise clients require compliance. Documents ignoring security standards for enterprise audiences signal inexperience.",
    calculation: "Gemini scores 1-10 informed by heuristic regulatory keyword matches from the pre-analysis. Weight: 20%.",
  },

  // ── Module 4: Audience Level ──────────────────────────────────────────────
  {
    term: "Target Audience Level",
    category: "Core Decision Modules",
    meaning: "Identifies who should read this — Developer, Manager, VP, or C-Suite — based on language and decision scope.",
    importance: "A C-Suite executive reading developer documentation wastes time. A developer reading strategic vision documents can't act on them.",
    calculation: "Gemini Layer 3 classification. Five weighted drivers evaluated using document text, fluff metrics, and data intensity from heuristic pre-pass.",
  },
  {
    term: "Strategic vs. Tactical Ratio",
    category: "Core Decision Modules",
    meaning: "Balance between high-level strategic vision and hands-on implementation details.",
    importance: "Pure strategy without tactics is useless for implementers. Pure tactics without strategy is useless for decision-makers.",
    calculation: "Gemini scores 1-10 by analyzing the balance of strategic vision vs. tactical implementation content. Weight: 30%.",
  },
  {
    term: "Financial Metric Density",
    category: "Core Decision Modules",
    meaning: "Presence of financial language like EBITDA, NPV, CapEx, ROI, TCO that targets financial decision-makers.",
    importance: "Documents with heavy financial metrics target budget holders. Their absence signals technical or operational audiences.",
    calculation: "Gemini scores 1-10 informed by heuristic financial keyword counts. Weight: 20%.",
  },
  {
    term: "Technical Jargon Density",
    category: "Core Decision Modules",
    meaning: "Amount of technical terminology (APIs, Docker, Python, microservices) vs. business language.",
    importance: "High technical jargon targets developers/architects. Business-friendly language targets managers and executives.",
    calculation: "Gemini scores 1-10 informed by heuristic technical keyword counts from the fluff analysis. Weight: 20%.",
  },
  {
    term: "Actionable Horizon",
    category: "Core Decision Modules",
    meaning: "Whether recommended actions are immediate ('do this today') or long-term ('3-year roadmap').",
    importance: "Short horizons suit operational teams. Long horizons suit strategic planners. Mismatched horizons reduce document utility.",
    calculation: "Gemini scores 1-10 by evaluating time references and planning horizons. Weight: 15%.",
  },
  {
    term: "Decision Scope",
    category: "Core Decision Modules",
    meaning: "Whether decisions are tool-level (manager) or business-model-level (C-Suite).",
    importance: "The scope of decisions determines who needs to read the document. Tool selection ≠ business model transformation.",
    calculation: "Gemini scores 1-10 by analyzing the scope and gravity of decisions discussed. Weight: 15%.",
  },

  // ── Module 5: Rarity Index ────────────────────────────────────────────────
  {
    term: "Rarity Index",
    category: "Core Decision Modules",
    meaning: "Measures content uniqueness: Commodity (conventional wisdom), Differentiated (some original value), or Category-Defining (truly novel).",
    importance: "Commodity content can be found for free anywhere. Category-Defining content is worth paying for and acting on immediately.",
    calculation: "Gemini Layer 4 synthesis. AI compares document content against its broad knowledge of common industry material to assess genuine novelty. Five weighted drivers.",
  },
  {
    term: "Primary Data Source",
    category: "Core Decision Modules",
    meaning: "Whether data comes from original research (surveys, experiments) or aggregated secondary sources.",
    importance: "Primary data is proprietary and harder to replicate, making the document more valuable and unique.",
    calculation: "Gemini scores 1-10 by assessing data originality and research methodology. Weight: 25%.",
  },
  {
    term: "Contrarian Factor",
    category: "Core Decision Modules",
    meaning: "Whether the document challenges conventional wisdom or simply aligns with current hype.",
    importance: "Contrarian insights that are well-supported are the most valuable type of content — they give the reader an edge.",
    calculation: "Gemini scores 1-10 by identifying positions that go against mainstream consensus with supporting evidence. Weight: 25%.",
  },
  {
    term: "Framework Novelty",
    category: "Core Decision Modules",
    meaning: "Whether the document uses standard frameworks (SWOT, Porter's Five Forces) or introduces original models.",
    importance: "Novel frameworks represent genuine intellectual contribution. Rehashing standard tools is commodity thinking.",
    calculation: "Gemini scores 1-10 by comparing frameworks against known standard models and assessing originality. Weight: 20%.",
  },
  {
    term: "Predictive Specificity",
    category: "Core Decision Modules",
    meaning: "Whether predictions are vague ('AI will grow') or specific and falsifiable ('GPU costs will drop 40% by Q3 2026').",
    importance: "Specific predictions demonstrate deep domain expertise and conviction. Vague predictions are risk-free filler.",
    calculation: "Gemini scores 1-10 by evaluating specificity, falsifiability, and boldness of predictions. Weight: 15%.",
  },
  {
    term: "Case Study Transparency",
    category: "Core Decision Modules",
    meaning: "Whether examples use named, verifiable companies or anonymous placeholders ('a large bank').",
    importance: "Named case studies can be verified and build credibility. Anonymous examples may be fabricated or embellished.",
    calculation: "Gemini scores 1-10 by assessing case study verifiability and transparency. Weight: 15%.",
  },

  // ── Content Forensics: Deception ──────────────────────────────────────────
  {
    term: "Manipulation Index",
    category: "Content Forensics",
    meaning: "Combined score (0-100) measuring the density and severity of manipulative language techniques in the document.",
    importance: "High manipulation scores indicate the document is designed to persuade emotionally rather than inform rationally.",
    calculation: "HYBRID: Heuristic engine counts weasel words, puffery, urgency, passive voice, and jargon (exact counts). Gemini then judges overall manipulation severity (0-100) considering context, intent, and how manipulative the patterns actually are — not just their quantity.",
  },
  {
    term: "Weasel Words",
    category: "Content Forensics",
    meaning: "Accountability-destroying phrases like 'arguably', 'up to', 'may contribute', 'potentially' that make claims unfalsifiable.",
    importance: "Weasel words let authors claim credit for successes while avoiding blame for failures. They're the linguistic equivalent of fine print.",
    calculation: "HEURISTIC: Pattern matching against a curated dictionary of ~25+ weasel phrases. Each occurrence counted with frequency. Fed into Gemini as context for manipulation scoring.",
  },
  {
    term: "Percentage Puffery",
    category: "Content Forensics",
    meaning: "Impressive-sounding metrics without baselines — e.g., '300% growth' without mentioning it went from 1 to 4.",
    importance: "Unanchored percentages create an illusion of scale. '500% ROI' is meaningless without knowing the investment amount and timeframe.",
    calculation: "HEURISTIC: Regex detection of percentage claims paired with growth/improvement language. Each unanchored claim is captured.",
  },
  {
    term: "False Urgency",
    category: "Content Forensics",
    meaning: "Artificial time pressure like 'window is closing', 'act now before competitors', 'critical window of opportunity'.",
    importance: "False urgency triggers emotional decision-making, bypassing rational cost-benefit analysis. It's a classic sales manipulation technique.",
    calculation: "HEURISTIC: Pattern matching for ~10+ urgency phrases and regex patterns. Count and matches provided to Gemini for context.",
  },
  {
    term: "Jargon Masking",
    category: "Content Forensics",
    meaning: "Complex buzzword phrases that conceal simple ideas — e.g., 'synergistic paradigm shift' instead of 'working together differently'.",
    importance: "Jargon masking creates the impression of sophistication while obscuring lack of substance. It inflates perceived value.",
    calculation: "HEURISTIC: Detection against a curated list of ~20+ multi-word buzzword combinations and unnecessarily complex terminology.",
  },

  // ── Content Forensics: Logical Fallacies ──────────────────────────────────
  {
    term: "Fallacy Density",
    category: "Content Forensics",
    meaning: "Number of logical fallacies detected per 1,000 words of text.",
    importance: "Higher density indicates weaker logical foundations. Documents with many fallacies should not be used for decision-making without independent verification.",
    calculation: "GEMINI: AI analyzes argument structure to identify fallacies. Density = total fallacies ÷ (word count ÷ 1,000). Unlike keyword matching, Gemini understands reasoning patterns.",
  },
  {
    term: "Straw Man Fallacy",
    category: "Content Forensics",
    meaning: "Attacking a weakened version of an opponent's argument rather than the actual position.",
    importance: "Straw man arguments indicate intellectual dishonesty and undermine comparative analysis credibility.",
    calculation: "GEMINI: AI identifies where the document misrepresents competing approaches or alternative views to make them easier to dismiss.",
  },
  {
    term: "False Dichotomy",
    category: "Content Forensics",
    meaning: "Binary framing like 'Adopt AI or go bankrupt' that eliminates nuanced middle-ground options.",
    importance: "False dichotomies pressure readers into predetermined conclusions by removing valid alternative paths.",
    calculation: "GEMINI: AI detects artificial either/or framing that eliminates nuanced alternatives, even when not using explicit 'either/or' keywords.",
  },
  {
    term: "Appeal to Authority",
    category: "Content Forensics",
    meaning: "Using 'As Gartner says...' or similar authority references without independent evidence.",
    importance: "Authority references are useful context but shouldn't substitute for actual data. Over-reliance signals weak independent analysis.",
    calculation: "GEMINI: AI identifies where authority citations are used as the sole justification without accompanying data or methodology.",
  },
  {
    term: "Post Hoc Fallacy",
    category: "Content Forensics",
    meaning: "Assuming causation from correlation — 'After implementing X, revenue grew 40%' doesn't prove X caused the growth.",
    importance: "Post hoc reasoning is the most common way case studies mislead. Correlation ≠ causation, especially in complex business environments.",
    calculation: "GEMINI: AI detects temporal claims ('after implementing... results improved') that imply causation without evidence of controlled comparison.",
  },
  {
    term: "Sunk Cost Fallacy",
    category: "Content Forensics",
    meaning: "Arguments to continue projects solely because of prior investment rather than future value.",
    importance: "Sunk cost reasoning leads to throwing good money after bad. Decisions should be based on future value, not past expenditure.",
    calculation: "GEMINI: AI detects arguments justifying continuation based on past investment rather than future value analysis.",
  },

  // ── Content Forensics: Fluff ──────────────────────────────────────────────
  {
    term: "Fluff Score",
    category: "Content Forensics",
    meaning: "Combined score (0-100) measuring the ratio of filler content to substantive information.",
    importance: "High fluff scores mean you're reading more words for less information. Low-fluff documents respect the reader's time.",
    calculation: "FULLY HEURISTIC: Weighted combination of Gunning Fog Index (40%), Adjective/Verb Ratio (30%), and inverse of Unique Data Points (30%). Pure computation — no AI needed.",
  },
  {
    term: "Gunning Fog Index",
    category: "Content Forensics",
    meaning: "Estimates the years of formal education needed to understand the text on first reading.",
    importance: "Unnecessarily complex writing often masks shallow thinking. The best ideas can be explained simply.",
    calculation: "HEURISTIC: Mathematical formula: 0.4 × [(words/sentences) + 100 × (complex_words/words)]. Complex words = words with >6 characters. Score <12 = accessible, >18 = academic.",
  },
  {
    term: "Adjective/Verb Ratio",
    category: "Content Forensics",
    meaning: "The ratio of descriptive words (adjectives/adverbs) to action words (verbs) in the document.",
    importance: "More adjectives than verbs means more description than substance. Action-oriented writing is more useful for decision-makers.",
    calculation: "HEURISTIC: Suffix-based approximation: words ending in -ly/-ive/-ous/-ful/-al (adjectives) ÷ words ending in -ing/-ed/-ize/-ate (verbs). Ratio > 3.0 = excessive.",
  },
  {
    term: "Buzzwords",
    category: "Content Forensics",
    meaning: "Marketing-oriented words like 'synergy', 'leverage', 'cutting-edge', 'revolutionary' that add perceived sophistication without meaning.",
    importance: "High buzzword density suggests the document prioritizes impression over information. Substance-rich documents use precise language.",
    calculation: "HEURISTIC: Pattern matching against a curated and regularly updated dictionary of ~40+ business buzzwords. Count per document.",
  },
  {
    term: "Action Verbs",
    category: "Content Forensics",
    meaning: "Concrete action words like 'implement', 'deploy', 'configure', 'measure', 'test' that indicate practical content.",
    importance: "Documents rich in action verbs are more likely to contain actionable guidance you can execute immediately.",
    calculation: "HEURISTIC: Pattern matching against a curated dictionary of ~30+ implementation-oriented action verbs.",
  },
  {
    term: "Unique Data Points",
    category: "Content Forensics",
    meaning: "Count of concrete, verifiable numbers, percentages, dates, and statistics in the document.",
    importance: "More unique data points = higher information density. Opinions are free; data costs effort to gather.",
    calculation: "HEURISTIC: Regex extraction of numerical values, percentages, dollar amounts, and dates. Duplicates removed for unique count.",
  },

  // ── Advanced: Implementation Readiness ────────────────────────────────────
  {
    term: "Implementation Readiness Score",
    category: "Advanced Assessment",
    meaning: "Score (1-10) measuring the gap between conceptual description and executable implementation.",
    importance: "A beautiful strategy deck that can't be implemented is worthless. This score tells you if you can actually DO what the document describes.",
    calculation: "GEMINI Layer 2: AI evaluates artifact quality (not just presence), timeline realism, resource specificity, and prerequisite completeness. Informed by data intensity findings from the heuristic pre-pass.",
  },
  {
    term: "Artifact Presence",
    category: "Advanced Assessment",
    meaning: "Checks for executable artifacts: code snippets, configuration files, checklists, architecture diagrams, templates, API definitions.",
    importance: "Documents with artifacts can be acted on immediately. Documents without them require additional work to become actionable.",
    calculation: "GEMINI: AI checks for each artifact type and assesses quality — a vague mention of 'architecture' is scored lower than an actual detailed diagram.",
  },
  {
    term: "Resource Clarity",
    category: "Advanced Assessment",
    meaning: "Whether specific roles and skills are defined (e.g., 'need 1 Data Engineer with 3+ years') vs. vague references.",
    importance: "Without clear resource requirements, you can't plan staffing or budget. Vague 'resources needed' delays project start.",
    calculation: "GEMINI: AI scores 1-10 by evaluating specificity of role definitions, skill requirements, and team composition guidance.",
  },
  {
    term: "Timeline Reality",
    category: "Advanced Assessment",
    meaning: "Whether timelines include specific dates and durations or use vague references like 'future state'.",
    importance: "Realistic timelines enable planning. Vague timelines indicate the author hasn't thought through execution complexity.",
    calculation: "GEMINI: AI scores 1-10 by assessing timeline specificity AND realism — can the proposed work actually be done in the stated timeframe?",
  },
  {
    term: "Prerequisite Check",
    category: "Advanced Assessment",
    meaning: "Clear statement of starting requirements (e.g., 'requires clean data lake and API gateway') vs. no mention.",
    importance: "Missing prerequisites are the #1 cause of project delays. Clear prerequisites enable realistic planning.",
    calculation: "GEMINI: AI scores 1-10 by evaluating completeness of prerequisite documentation and whether hidden assumptions exist.",
  },

  // ── Advanced: Obsolescence Risk ───────────────────────────────────────────
  {
    term: "Obsolescence Risk Score",
    category: "Advanced Assessment",
    meaning: "Score (0-100) indicating how likely the document's recommendations will become outdated in the near term.",
    importance: "In fast-moving fields like AI, recommendations older than 12 months may already be outdated. This score flags stale advice.",
    calculation: "GEMINI Layer 2: AI uses its knowledge of current technology landscape (2026) to evaluate whether recommendations are current. More accurate than static keyword lists for fast-moving fields.",
  },
  {
    term: "Outdated References",
    category: "Advanced Assessment",
    meaning: "Technologies mentioned that are no longer current best practice.",
    importance: "Recommendations based on outdated tech will lead to suboptimal implementations and higher migration costs later.",
    calculation: "GEMINI: AI identifies outdated technologies and practices using its training knowledge. Can detect subtle obsolescence that static lists miss.",
  },
  {
    term: "Missing Current Practices",
    category: "Advanced Assessment",
    meaning: "Important current technologies and practices that the document doesn't mention.",
    importance: "Omitting current best practices suggests the author isn't current with the field, reducing recommendation credibility.",
    calculation: "GEMINI: AI checks for absence of expected modern practices relevant to the document's topic. Dynamic — not limited to a fixed checklist.",
  },

  // ── Advanced: Hype vs Reality ─────────────────────────────────────────────
  {
    term: "Hype Score",
    category: "Advanced Assessment",
    meaning: "Optimism score (0-100) measuring the balance between promotional language and honest risk acknowledgment.",
    importance: "Credible documents acknowledge what could go wrong. Pure optimism without risk discussion is sales material, not analysis.",
    calculation: "GEMINI Layer 4 synthesis: AI considers all prior findings (deception, bias, fallacies, sentiment) to make a meta-judgment. 60-80% positive = credible. >90% with zero risk = 'Sales Propaganda'.",
  },
  {
    term: "Positive Sentiment %",
    category: "Advanced Assessment",
    meaning: "Percentage of the document's language that is positive, promotional, or optimistic.",
    importance: "Extreme positivity (>85%) with no counterbalance indicates bias toward presenting an unrealistically positive picture.",
    calculation: "GEMINI: AI-powered sentiment analysis counting positive language vs. total evaluative language. More nuanced than keyword counting.",
  },
  {
    term: "Risk Mentions",
    category: "Advanced Assessment",
    meaning: "Count of references to risks, challenges, limitations, and potential failure modes.",
    importance: "Credible documents discuss what could go wrong. Zero risk mentions in a business document is itself a red flag.",
    calculation: "GEMINI: AI identifies and counts risk-related content including implicit risk discussions that don't use explicit 'risk' keywords.",
  },
  {
    term: "Failure Acknowledgments",
    category: "Advanced Assessment",
    meaning: "Presence of sections or statements acknowledging where approaches might fail or have failed.",
    importance: "Willingness to discuss failure dramatically increases credibility and helps readers prepare contingency plans.",
    calculation: "GEMINI: AI detects failure acknowledgment patterns including lessons learned, limitations sections, and honest 'when this doesn't work' discussions.",
  },

  // ── Advanced: Regulatory & Ethics ─────────────────────────────────────────
  {
    term: "Safety Score",
    category: "Advanced Assessment",
    meaning: "Combined score (0-100) assessing regulatory compliance awareness and ethical consideration in the document.",
    importance: "AI implementations without regulatory or ethical frameworks face legal liability, reputational damage, and potential fines.",
    calculation: "HYBRID: Heuristic counts regulatory, ethical, and privacy keyword mentions (hard numbers). Gemini Layer 1 then judges overall safety level and identifies contextual red flags that keyword matching alone would miss.",
  },
  {
    term: "Regulatory Mentions",
    category: "Advanced Assessment",
    meaning: "References to compliance frameworks like GDPR, EU AI Act, CCPA, SOC2, HIPAA, ISO 27001.",
    importance: "Regulatory awareness indicates the author understands real-world deployment requirements, not just technical feasibility.",
    calculation: "HEURISTIC: Pattern matching for ~13 regulation names and compliance framework references. Exact matches counted.",
  },
  {
    term: "Ethical Mentions",
    category: "Advanced Assessment",
    meaning: "References to bias mitigation, fairness, transparency, explainability, and responsible AI practices.",
    importance: "Ethical AI is increasingly a regulatory requirement (EU AI Act). Documents ignoring ethics will produce non-compliant implementations.",
    calculation: "HEURISTIC: Pattern matching for ~10 ethics-related keywords. Exact matches counted.",
  },
  {
    term: "Red Flags (Safety)",
    category: "Advanced Assessment",
    meaning: "Critical omissions like proposing data scraping without compliance or AI deployment without bias assessment.",
    importance: "Red flags indicate potential legal or ethical violations that could result in fines, lawsuits, or reputational damage.",
    calculation: "GEMINI: AI analyzes the document's proposals in context — identifies risky activities proposed without corresponding compliance or ethics frameworks. Requires contextual understanding beyond keyword matching.",
  },

  // ── Composition & Visual/Data Intensity ───────────────────────────────────
  {
    term: "Visual Intensity",
    category: "Composition",
    meaning: "Score (1-10) measuring the document's use of diagrams, charts, graphs, infographics, and visual elements.",
    importance: "Well-visualized documents communicate complex ideas more effectively. But visuals without data can mask shallow analysis.",
    calculation: "GEMINI MULTIMODAL: AI examines actual PDF page images (up to 8 pages rendered at 768px) to see and assess charts, diagrams, infographics, and formatting richness. Not limited to text keyword references — can see captionless visuals, embedded charts, and formatting quality.",
  },
  {
    term: "Data Intensity",
    category: "Composition",
    meaning: "Score (1-10) measuring the density of quantitative evidence: tables, citations, statistics.",
    importance: "Data-rich documents provide stronger evidence for claims. Opinion without data is just... opinion.",
    calculation: "FULLY HEURISTIC: Count of tables + citations + statistics, normalized to 1-10 scale. Deterministic and reproducible.",
  },
  {
    term: "Diagrams",
    category: "Composition",
    meaning: "Count of visual elements including charts, graphs, diagrams, and infographics in the document.",
    importance: "Diagrams aid comprehension of complex systems, architectures, and processes. Their presence indicates presentation effort.",
    calculation: "GEMINI MULTIMODAL: AI counts visual elements seen in page images, plus text references to figures and diagrams.",
  },
  {
    term: "Citations",
    category: "Composition",
    meaning: "Count of academic-style citations and source references.",
    importance: "More citations indicate greater research rigor and the ability to verify claims independently.",
    calculation: "HEURISTIC: Regex detection of [Author, Year] patterns, numbered references [1], 'et al.', and bibliography-style citations.",
  },
  {
    term: "Tables",
    category: "Composition",
    meaning: "Count of tabular data references in the document.",
    importance: "Tables provide structured quantitative evidence that is easy to compare and verify.",
    calculation: "HEURISTIC: Detection of 'table' keyword, pipe-delimited patterns, and structured data formats.",
  },
  {
    term: "Statistics",
    category: "Composition",
    meaning: "Count of specific numerical claims, percentages, and financial figures.",
    importance: "Statistical claims add precision and credibility. More statistics = higher evidence density.",
    calculation: "HEURISTIC: Regex extraction of percentages (X%), dollar amounts ($X), multipliers (Xx), and specific quantities.",
  },

  // ── Bias Detection ────────────────────────────────────────────────────────
  {
    term: "Overall Bias Score",
    category: "Bias Detection",
    meaning: "Combined score (0-100) measuring the presence of cognitive biases that undermine document credibility.",
    importance: "Even well-intentioned authors have blind spots. Understanding which biases are present helps readers compensate.",
    calculation: "GEMINI Layer 2: AI evaluates evidence selectivity, narrative framing, and argument balance. Informed by fallacy and deception findings from Layer 1. Severity-weighted scoring.",
  },
  {
    term: "Confirmation Bias",
    category: "Bias Detection",
    meaning: "Only presenting evidence that confirms a predetermined conclusion while ignoring contradicting data.",
    importance: "Creates unrealistic expectations by showing only successes. Readers may commit resources based on incomplete evidence.",
    calculation: "GEMINI: AI identifies one-sided narratives by understanding the argument structure and detecting absence of counterevidence. More accurate than counting success/failure word ratios.",
  },
  {
    term: "Survival Bias",
    category: "Bias Detection",
    meaning: "Only analyzing successful companies/projects while ignoring the many that failed using similar approaches.",
    importance: "Survival bias dramatically overestimates success probability. For every success story, there may be 100 invisible failures.",
    calculation: "GEMINI: AI recognizes when only 'winners' are discussed in case studies and sector analyses, understanding that failed examples are conspicuously absent.",
  },
  {
    term: "Selection Bias",
    category: "Bias Detection",
    meaning: "Cherry-picking data, time periods, or examples that support a predetermined conclusion.",
    importance: "Selected data misleads about general applicability. What works in the selected sample may not work elsewhere.",
    calculation: "GEMINI: AI detects strategically chosen examples, narrow data ranges, and conveniently scoped analyses that support the thesis.",
  },
  {
    term: "Recency Bias",
    category: "Bias Detection",
    meaning: "Over-weighting recent events and trends while ignoring historical patterns and cyclical behavior.",
    importance: "Technology hype cycles repeat. Ignoring history leads to over-investment at peaks and missed opportunities at troughs.",
    calculation: "GEMINI: AI assesses temporal balance — are recent events presented without historical context or cyclical pattern acknowledgment?",
  },
  {
    term: "Authority Bias",
    category: "Bias Detection",
    meaning: "Over-reliance on expert opinions (Gartner, Forrester, Harvard) without independent empirical validation.",
    importance: "Even respected authorities can be wrong. Independent data should corroborate authority claims, not replace evidence.",
    calculation: "GEMINI: AI identifies where authority citations serve as primary evidence without independent data or methodology discussion.",
  },

  // ── Key Findings ──────────────────────────────────────────────────────────
  {
    term: "Key Findings",
    category: "Key Findings",
    meaning: "The most notable and surprising claims extracted from the document by AI analysis.",
    importance: "Highlights the information most worth your attention, saving time on lengthy documents. AI identifies what's genuinely novel, not just sentences with numbers.",
    calculation: "GEMINI Layer 4: AI reads the full document with context from all prior analysis layers and identifies 3-5 genuinely surprising or noteworthy findings based on comprehension, not pattern matching.",
  },
  {
    term: "Contrarian Tag",
    category: "Key Findings",
    meaning: "This finding contradicts conventional wisdom or current market consensus.",
    importance: "Contrarian insights, when well-supported, are the most valuable type of information — they provide competitive advantage.",
    calculation: "GEMINI: AI identifies positions that go against mainstream consensus based on its knowledge of common industry viewpoints.",
  },
  {
    term: "Quantified Tag",
    category: "Key Findings",
    meaning: "This finding includes specific numbers, percentages, or data that can be independently verified.",
    importance: "Quantified claims are falsifiable — you can check them. Unquantified claims are opinions that can't be disproven.",
    calculation: "GEMINI: AI identifies findings containing specific measurable data points that enable independent verification.",
  },

  // ── Methodology ───────────────────────────────────────────────────────────
  {
    term: "Hybrid Analysis Engine",
    category: "Methodology",
    meaning: "DocDetector uses a two-tier architecture: a heuristic engine for counting and pattern matching, plus Gemini 2.0 Flash AI for judgment, classification, and comprehension tasks.",
    importance: "The heuristic engine provides instant, free, deterministic counts (word frequencies, ratios, keyword matches). Gemini provides contextual judgment that requires understanding language, arguments, and intent. Together they produce more accurate results than either alone.",
    calculation: "Heuristic pre-pass runs first (~100ms, free). Results feed into 4 sequential Gemini API calls, each building on the last. If Gemini is unavailable, the system falls back to heuristic-only analysis.",
  },
  {
    term: "Layered Analysis Pipeline",
    category: "Methodology",
    meaning: "Gemini analysis runs in 4 sequential layers where each layer's results are injected into the next layer's prompt, creating an increasingly informed analysis.",
    importance: "Layer chaining ensures later judgments (like bias detection) are informed by earlier findings (like deception patterns). This produces more coherent and accurate results than independent parallel calls.",
    calculation: "Layer 1: Raw forensics (temp 0.1). Layer 2: Informed analysis — bias, obsolescence, readiness (temp 0.2). Layer 3: Strategic classification — provider/consumer, scales, audience (temp 0.25). Layer 4: Synthesis — hype, rarity, findings, trust score, summary (temp 0.3).",
  },
  {
    term: "Weighted Composite Score",
    category: "Methodology",
    meaning: "The standard scoring formula used across all classification modules: Score = Σ(rating × weight), where each driver has a predefined weight.",
    importance: "Ensures consistent, quantifiable assessment across all modules. Weights reflect the relative importance of each factor.",
    calculation: "Each driver is scored 1-10 by Gemini AI (or heuristic for fallback). The score is multiplied by the driver's weight (which sums to 1.0 per module). The result is normalized to 0-100.",
  },
  {
    term: "Driver",
    category: "Methodology",
    meaning: "An individual analytical dimension within a module. Each classification module has 5 weighted drivers that contribute to its composite score.",
    importance: "Drivers break down complex assessments into specific, measurable dimensions that can be individually examined and challenged.",
    calculation: "Each driver is scored 1-10 by Gemini AI based on contextual analysis of the document. The weight (expressed as %) determines how much it contributes to the module's total.",
  },
  {
    term: "Temperature",
    category: "Methodology",
    meaning: "A parameter controlling the randomness of Gemini AI's responses. Lower = more deterministic, higher = more creative.",
    importance: "Factual analysis (forensics) uses low temperature (0.1) for consistency. Creative synthesis (key findings, summaries) uses higher temperature (0.3) for insightful output.",
    calculation: "Layer 1: 0.1 (factual). Layer 2: 0.2 (informed judgment). Layer 3: 0.25 (classification). Layer 4: 0.3 (creative synthesis).",
  },
  {
    term: "Document Fitness Check",
    category: "Methodology",
    meaning: "Before analysis begins, Gemini performs a quick classification of the uploaded document to verify it falls within DocDetector's scope: technology vendor and advisory documents (consulting proposals, vendor pitches, training brochures, whitepapers, advisory decks) in the domains of AI, Data, Cloud, Digital Transformation, and Governance.",
    importance: "Prevents wasted analysis time and misleading results on documents the engine was not designed for, such as legal contracts, financial reports, HR policies, or academic papers.",
    calculation: "Gemini Layer 0 (pre-analysis): First ~5000 characters are sent to Gemini with a classification prompt. Returns fit/not-fit, document type, domain, and reason. If not fit, a rejection popup is shown and no report is generated. If the check itself fails, the document is allowed through.",
  },
  {
    term: "Heuristic Fallback",
    category: "Methodology",
    meaning: "When Gemini AI is unavailable (no API key, rate limit, or API error), the system automatically falls back to a fully heuristic analysis engine.",
    importance: "Ensures the app never shows a blank report. The heuristic engine provides reasonable (though less nuanced) results using keyword matching, pattern detection, and mathematical formulas.",
    calculation: "All KPIs have heuristic implementations using hardcoded dictionaries and regex patterns. These produce deterministic, consistent results but lack the contextual understanding that Gemini provides.",
  },
];

/** All unique categories in the glossary, in display order */
export const GLOSSARY_CATEGORIES = [
  "Overall",
  "Core Decision Modules",
  "Content Forensics",
  "Advanced Assessment",
  "Composition",
  "Bias Detection",
  "Key Findings",
  "Methodology",
] as const;
